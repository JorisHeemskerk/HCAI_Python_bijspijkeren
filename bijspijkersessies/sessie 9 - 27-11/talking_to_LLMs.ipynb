{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee80849f",
   "metadata": {},
   "source": [
    "# Praten met LLMs\n",
    "\n",
    "Iedereen weet hoe ze moeten praten met LLMs als ChatGPT, Gemini, Claude, etc.: via een website. Dat is voor individueel gebruik natuurlijk perfect, maar wat als je een LLM voor een eigen project in wil zetten? Dan kan dat niet via de browser, dit doen we met een API. Hieronder heb ik een voorbeeldje om te praten met een model van [Nebius Studio](https://tokenfactory.nebius.com/). Dit is een platform waar je gratis 1 euro krijgt om met LLMs te praten. Dit is waarschijnlijk niet genoeg voor je project, maar voor kleine tests werkt dat uitstekend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12a0b8",
   "metadata": {},
   "source": [
    "Eerst de imports dan maar: Nebius werkt op de zelfde manier als Open AI, dit is een soort standaard geworden voor vele LLM API aanbieders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a48887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0547b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7fc8f",
   "metadata": {},
   "source": [
    "Als we werken met een API hebben we een *key* nodig. Dit is een verificatiesleutel die je stuurt naar de API waarmee je laat weten dat jij het bent.\n",
    "\n",
    "Ik heb op de nebius studio website een key aangemaakt en toegevoegd aan mijn windows systeem via de volgende stappen:\n",
    "- Press Start -> type “Environment Variables” -> open “Edit the system environment variables”\n",
    "- Click Environment Variables\n",
    "- Under User variables (or System variables):\n",
    "  - Click New\n",
    "  - Variable name: HCAI_NEBIUS_API_KEY\n",
    "  - Variable value: your key\n",
    "- Press OK -> restart your notebook\\\n",
    "*(Steps generated with ChatGPT)*\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">LET OP: Je wil NOOIT je API key delen. Hiermee kunnen anderen mensen jou geld uitgeven</span>   \n",
    "\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">Push de key dus nooit naar GitHub. Ook niet als je deze ergens in een jupyter notebook hebt gebruikt. Dit valt allemaal terug te halen. Reset dan eerst je notebook en zet deze daarna pas in Git.</span>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a33a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEBIUS_API_KEY = os.environ.get(\"HCAI_NEBIUS_API_KEY\") # <- Ik heb mijn API key `HCAI_NEBIUS_API_KEY` genoemd, als die van jou anders heet, pas deze dan aan\n",
    "\n",
    "if not NEBIUS_API_KEY:\n",
    "    raise ValueError(\"NEBIUS_API_KEY is not set in environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509359cc",
   "metadata": {},
   "source": [
    "Nu kunnen we contact maken met de API. Hiervoor maken we een client aan. De client is onze verbinding met de API. We hoeven hier nog niet ons model te specificeren, dat komt straks pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcab353",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=NEBIUS_API_KEY,\n",
    "    base_url=\"https://api.studio.nebius.ai/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e78749",
   "metadata": {},
   "source": [
    "Oke, nu kunnen we een functie gaan schrijven die ene vraag stelt aan het model en het antwoord teruggeeft. Hieronder een voorbeeld:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_nebius(model: str, prompt: str)-> tuple[object, str, str]:\n",
    "    \"\"\"\n",
    "    Sends a user message to a Nebius Studio LLM and returns the model's reply.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt} \n",
    "        ],\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[ # Hier geven we aan hoe het model de prompt van de user moet ontvangen.\n",
    "            # hier kunnen we een system prompt meegeven. \n",
    "            # Dit kan bijvoorbeeld een instructie zijn voor hoe het model zich moet gedragen tegenover de gebruiker.\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"SYSTEM_PROMPT\"\"\" \n",
    "            },\n",
    "            # Hier geven we de user prompt.\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # De LLM geeft veel informatie terug, maar we zijn alleen geïnteresseerd in de response tekst. \n",
    "    # We geven eerst alle output, dan alle output als een json format, en daarna alleen de message response.\n",
    "    return response, response.to_json(), response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643dee7f",
   "metadata": {},
   "source": [
    "Oke, laten we een simpele vraag stellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Op dit moment is dit model het goedkoopst\n",
    "model = \"google/gemma-2-2b-it\"\n",
    "response, json_response, text_reply = ask_nebius(model, \"Give me the python code for a hello world example.\")\n",
    "\n",
    "print(\"Model reply:\\n\", text_reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96050cf5",
   "metadata": {},
   "source": [
    "Hieronder heb ik de output die ik zelf kreeg geplakt in markdown, zodat de opmaak klopt:\n",
    "\n",
    "---\n",
    "\n",
    "Model reply:\n",
    " ```python\n",
    "print(\"Hello, world!\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "* **`print()`:** This is a built-in Python function that displays whatever you put inside its parentheses on the screen.\n",
    "* **\"Hello, world!\"** : This is a string, a sequence of characters enclosed within quotation marks.  This is the message you want to display.\n",
    "\n",
    "\n",
    "**To run this code:**\n",
    "\n",
    "1. **Save it:** Create a new file named `hello_world.py` and paste this code into it.\n",
    "2. **Open a terminal:** Navigate to the directory containing the file using the `cd` command.\n",
    "3. **Run the code:** Type `python hello_world.py` and press Enter.\n",
    "\n",
    "\n",
    "You'll see \"Hello, world!\" printed in your terminal. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCAI_python_TA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
